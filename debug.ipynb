{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import griddata as gd\n",
    "\n",
    "net, const_load_household, const_load_heatpump, time_steps, df_household_prognosis, df_season_heatpump_prognosis, heatpump_scaling_factors_df, T_amb = gd.setup_grid_powertech25(season='winter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Household ConstControl indices:\", const_load_household.element_index)\n",
    "print(\"Heat Pump ConstControl indices:\", const_load_heatpump.element_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               name  bus   p_mw    q_mvar  const_z_percent  const_i_percent  \\\n",
      "0    LV4.101 Load 1   32  0.004  0.001581              0.0              0.0   \n",
      "1   LV4.101 Load 30    6  0.003  0.001186              0.0              0.0   \n",
      "2        DEACTIVATE   19  0.000  0.000000              0.0              0.0   \n",
      "3        DEACTIVATE   14  0.000  0.000000              0.0              0.0   \n",
      "4   LV4.101 Load 18   11  0.006  0.002371              0.0              0.0   \n",
      "5   LV4.101 Load 20   17  0.006  0.002371              0.0              0.0   \n",
      "6    LV4.101 Load 4   31  0.004  0.001581              0.0              0.0   \n",
      "7   LV4.101 Load 16   33  0.004  0.001581              0.0              0.0   \n",
      "8   LV4.101 Load 22   28  0.003  0.001186              0.0              0.0   \n",
      "9    LV4.101 Load 6    4  0.003  0.001186              0.0              0.0   \n",
      "10  LV4.101 Load 19    8  0.004  0.001581              0.0              0.0   \n",
      "11       DEACTIVATE    9  0.000  0.000000              0.0              0.0   \n",
      "12  LV4.101 Load 25   13  0.006  0.002371              0.0              0.0   \n",
      "13  LV4.101 Load 27   16  0.004  0.001581              0.0              0.0   \n",
      "14       DEACTIVATE   34  0.000  0.000000              0.0              0.0   \n",
      "15  LV4.101 Load 23   24  0.006  0.002371              0.0              0.0   \n",
      "16  LV4.101 Load 29   22  0.003  0.001186              0.0              0.0   \n",
      "17  LV4.101 Load 14   21  0.003  0.001186              0.0              0.0   \n",
      "18  LV4.101 Load 26   21  0.003  0.001186              0.0              0.0   \n",
      "19  LV4.101 Load 31   10  0.003  0.001186              0.0              0.0   \n",
      "20  LV4.101 Load 33   20  0.004  0.001581              0.0              0.0   \n",
      "21    HP.101 Load 2   29  0.003  0.001186              0.0              0.0   \n",
      "22   LV4.101 Load 3   29  0.000  0.001186              0.0              0.0   \n",
      "23   LV4.101 Load 5    5  0.006  0.002371              0.0              0.0   \n",
      "24  LV4.101 Load 21   27  0.004  0.001581              0.0              0.0   \n",
      "25  LV4.101 Load 32   23  0.004  0.001581              0.0              0.0   \n",
      "26   LV4.101 Load 7   25  0.004  0.001581              0.0              0.0   \n",
      "27   LV4.101 Load 9    7  0.004  0.001581              0.0              0.0   \n",
      "28  LV4.101 Load 10    1  0.004  0.001581              0.0              0.0   \n",
      "29  LV4.101 Load 13    3  0.004  0.001581              0.0              0.0   \n",
      "30  LV4.101 Load 28   12  0.004  0.001581              0.0              0.0   \n",
      "31   LV4.101 Load 8   26  0.006  0.002371              0.0              0.0   \n",
      "32  LV4.101 Load 15   30  0.003  0.001186              0.0              0.0   \n",
      "33  LV4.101 Load 34   35  0.017  0.006719              0.0              0.0   \n",
      "34  LV4.101 Load 35   36  0.011  0.004347              0.0              0.0   \n",
      "35  LV4.101 Load 36   37  0.011  0.004347              0.0              0.0   \n",
      "36  LV4.101 Load 37   39  0.017  0.006719              0.0              0.0   \n",
      "37  LV4.101 Load 38   40  0.012  0.004743              0.0              0.0   \n",
      "38  LV4.101 Load 39   41  0.018  0.007114              0.0              0.0   \n",
      "39  LV4.101 Load 40   42  0.013  0.005138              0.0              0.0   \n",
      "40  LV4.101 Load 41   43  0.009  0.003557              0.0              0.0   \n",
      "\n",
      "      sn_mva  scaling  in_service type   subnet min_p_mw profile max_p_mw  \\\n",
      "0   0.004301      1.0        True  NaN  LV4.101      NaN    H0-B      NaN   \n",
      "1   0.003226      1.0        True  NaN  LV4.101      NaN    H0-A      NaN   \n",
      "2   0.008602      1.0        True  NaN  LV4.101      NaN    G1-A      NaN   \n",
      "3   0.003226      1.0        True  NaN  LV4.101      NaN    H0-L      NaN   \n",
      "4   0.006452      1.0        True  NaN  LV4.101      NaN    H0-G      NaN   \n",
      "5   0.006452      1.0        True  NaN  LV4.101      NaN    H0-A      NaN   \n",
      "6   0.004301      1.0        True  NaN  LV4.101      NaN    H0-A      NaN   \n",
      "7   0.004301      1.0        True  NaN  LV4.101      NaN    H0-L      NaN   \n",
      "8   0.003226      1.0        True  NaN  LV4.101      NaN    H0-A      NaN   \n",
      "9   0.003226      1.0        True  NaN  LV4.101      NaN    H0-B      NaN   \n",
      "10  0.004301      1.0        True  NaN  LV4.101      NaN    H0-G      NaN   \n",
      "11  0.003226      1.0        True  NaN  LV4.101      NaN    H0-B      NaN   \n",
      "12  0.006452      1.0        True  NaN  LV4.101      NaN    H0-L      NaN   \n",
      "13  0.004301      1.0        True  NaN  LV4.101      NaN    H0-L      NaN   \n",
      "14  0.003226      1.0        True  NaN  LV4.101      NaN    H0-G      NaN   \n",
      "15  0.006452      1.0        True  NaN  LV4.101      NaN    H0-L      NaN   \n",
      "16  0.003226      1.0        True  NaN  LV4.101      NaN    H0-B      NaN   \n",
      "17  0.003226      1.0        True  NaN  LV4.101      NaN    H0-L      NaN   \n",
      "18  0.003226      1.0        True  NaN  LV4.101      NaN    H0-B      NaN   \n",
      "19  0.003226      1.0        True  NaN  LV4.101      NaN    H0-B      NaN   \n",
      "20  0.004301      1.0        True  NaN  LV4.101      NaN    H0-A      NaN   \n",
      "21  0.003226      1.0        True  NaN  LV4.101      NaN    H0-L      NaN   \n",
      "22  0.003226      1.0        True  NaN  LV4.101      NaN    H0-G      NaN   \n",
      "23  0.006452      1.0        True  NaN  LV4.101      NaN    H0-B      NaN   \n",
      "24  0.004301      1.0        True  NaN  LV4.101      NaN    H0-B      NaN   \n",
      "25  0.004301      1.0        True  NaN  LV4.101      NaN    H0-G      NaN   \n",
      "26  0.004301      1.0        True  NaN  LV4.101      NaN    H0-G      NaN   \n",
      "27  0.004301      1.0        True  NaN  LV4.101      NaN    H0-G      NaN   \n",
      "28  0.004301      1.0        True  NaN  LV4.101      NaN    H0-B      NaN   \n",
      "29  0.004301      1.0        True  NaN  LV4.101      NaN    H0-A      NaN   \n",
      "30  0.004301      1.0        True  NaN  LV4.101      NaN    H0-L      NaN   \n",
      "31  0.006452      1.0        True  NaN  LV4.101      NaN    H0-B      NaN   \n",
      "32  0.003226      1.0        True  NaN  LV4.101      NaN    H0-G      NaN   \n",
      "33  0.018280      1.0        True  NaN  LV4.101      NaN    G4-A      NaN   \n",
      "34  0.011828      1.0        True  NaN  LV4.101      NaN    G2-A      NaN   \n",
      "35  0.011828      1.0        True  NaN  LV4.101      NaN    G4-A      NaN   \n",
      "36  0.018280      1.0        True  NaN  LV4.101      NaN    G6-A      NaN   \n",
      "37  0.012903      1.0        True  NaN  LV4.101      NaN    G2-A      NaN   \n",
      "38  0.019355      1.0        True  NaN  LV4.101      NaN    G4-B      NaN   \n",
      "39  0.013978      1.0        True  NaN  LV4.101      NaN    G1-A      NaN   \n",
      "40  0.009677      1.0        True  NaN  LV4.101      NaN    G1-C      NaN   \n",
      "\n",
      "   voltLvl max_q_mvar min_q_mvar controllable  \n",
      "0        7        NaN        NaN        False  \n",
      "1        7        NaN        NaN        False  \n",
      "2        7        NaN        NaN          NaN  \n",
      "3        7        NaN        NaN          NaN  \n",
      "4        7        NaN        NaN        False  \n",
      "5        7        NaN        NaN        False  \n",
      "6        7        NaN        NaN        False  \n",
      "7        7        NaN        NaN        False  \n",
      "8        7        NaN        NaN        False  \n",
      "9        7        NaN        NaN        False  \n",
      "10       7        NaN        NaN        False  \n",
      "11       7        NaN        NaN          NaN  \n",
      "12       7        NaN        NaN        False  \n",
      "13       7        NaN        NaN        False  \n",
      "14       7        NaN        NaN          NaN  \n",
      "15       7        NaN        NaN        False  \n",
      "16       7        NaN        NaN        False  \n",
      "17       7        NaN        NaN        False  \n",
      "18       7        NaN        NaN        False  \n",
      "19       7        NaN        NaN        False  \n",
      "20       7        NaN        NaN        False  \n",
      "21       7        NaN        NaN         True  \n",
      "22       7        NaN        NaN        False  \n",
      "23       7        NaN        NaN        False  \n",
      "24       7        NaN        NaN        False  \n",
      "25       7        NaN        NaN        False  \n",
      "26       7        NaN        NaN        False  \n",
      "27       7        NaN        NaN        False  \n",
      "28       7        NaN        NaN        False  \n",
      "29       7        NaN        NaN        False  \n",
      "30       7        NaN        NaN        False  \n",
      "31       7        NaN        NaN        False  \n",
      "32       7        NaN        NaN        False  \n",
      "33       7        NaN        NaN        False  \n",
      "34       7        NaN        NaN        False  \n",
      "35       7        NaN        NaN        False  \n",
      "36       7        NaN        NaN        False  \n",
      "37       7        NaN        NaN        False  \n",
      "38       7        NaN        NaN        False  \n",
      "39       7        NaN        NaN        False  \n",
      "40       7        NaN        NaN        False  \n"
     ]
    }
   ],
   "source": [
    "print(net.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add all buses as nodes\n",
    "for bus in net.bus.index:\n",
    "    G.add_node(bus)\n",
    "\n",
    "# Add edges based on line connections with edge index as an attribute\n",
    "line_edges = {}\n",
    "for idx, line in enumerate(net.line.itertuples()):\n",
    "    from_bus = line.from_bus\n",
    "    to_bus = line.to_bus\n",
    "    edge = (from_bus, to_bus)\n",
    "    G.add_edge(from_bus, to_bus)\n",
    "    line_edges[edge] = f\"Line {idx+1}\"\n",
    "\n",
    "# Add edges for transformer connections with edge index as an attribute\n",
    "trafo_edges = {}\n",
    "for idx, trafo in enumerate(net.trafo.itertuples()):\n",
    "    hv_bus = trafo.hv_bus\n",
    "    lv_bus = trafo.lv_bus\n",
    "    edge = (hv_bus, lv_bus)\n",
    "    G.add_edge(hv_bus, lv_bus)\n",
    "    trafo_edges[edge] = f\"Trafo {idx}\"\n",
    "\n",
    "# Combine all edge indices into one dictionary\n",
    "edge_labels = {**line_edges, **trafo_edges}\n",
    "\n",
    "# Find the root bus (e.g., the slack bus or transformer bus)\n",
    "root_bus = net.ext_grid.bus.iloc[0]\n",
    "\n",
    "# Debugging: Ensure the root bus exists in the graph\n",
    "if root_bus not in G.nodes:\n",
    "    print(f\"Warning: Root bus {root_bus} is not in the graph.\")\n",
    "    print(f\"Available nodes: {list(G.nodes)}\")\n",
    "else:\n",
    "    print(f\"Root bus {root_bus} found.\")\n",
    "\n",
    "# Generate a topological sort to ensure hierarchy\n",
    "levels = {node: 0 for node in G.nodes}\n",
    "visited = set()\n",
    "\n",
    "def assign_levels(node, level):\n",
    "    if node in visited:\n",
    "        return\n",
    "    visited.add(node)\n",
    "    levels[node] = level\n",
    "    for neighbor in G.neighbors(node):\n",
    "        assign_levels(neighbor, level + 1)\n",
    "\n",
    "# Assign levels starting from the root bus\n",
    "assign_levels(root_bus, 0)\n",
    "\n",
    "# Define a position based on levels with increased vertical spacing\n",
    "pos = {}\n",
    "nodes_by_level = {}\n",
    "vertical_spacing = 15  # Increase vertical spacing to 15 units\n",
    "\n",
    "for node, level in levels.items():\n",
    "    if level not in nodes_by_level:\n",
    "        nodes_by_level[level] = []\n",
    "    nodes_by_level[level].append(node)\n",
    "\n",
    "for level, nodes in nodes_by_level.items():\n",
    "    y = -level * vertical_spacing  # Adjusted vertical spacing\n",
    "    x_positions = range(len(nodes))\n",
    "    for x, node in zip(x_positions, nodes):\n",
    "        pos[node] = (x, y)\n",
    "\n",
    "# Plot the graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "nx.draw(\n",
    "    G,\n",
    "    pos,\n",
    "    with_labels=True,\n",
    "    node_size=500,\n",
    "    node_color=\"lightblue\",\n",
    "    font_size=10,\n",
    "    arrowsize=10,\n",
    ")\n",
    "\n",
    "# Highlight the root bus\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=[root_bus], node_color=\"red\", node_size=700)\n",
    "\n",
    "# Add edge labels\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8, label_pos=0.5)\n",
    "\n",
    "plt.title(\"Hierarchical Representation of the Grid with Transformer Connections and Edge Indices\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file (replace 'your_file.csv' with the actual file path)\n",
    "file_path = 'householdPrognosis.csv'\n",
    "df = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(\"First few rows of the data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display the header (column names) of the dataframe\n",
    "print(\"\\nColumn names (Header):\")\n",
    "print(df.columns)\n",
    "\n",
    "# Print the length of the 'dayOfWeek' column\n",
    "print(\"\\nLength of the 'dayOfWeek' column:\")\n",
    "print(df['meanP'].count())  # .count() counts non-null entries in the column\n",
    "\n",
    "# Print the last two values in the 'dayOfWeek' column\n",
    "print(\"\\nLast two values in the 'dayOfWeek' column:\")\n",
    "print(df['meanP'].tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Filter the data for rows where season is 'winter'\n",
    "winter_data = df[df['season'] == 'winter']\n",
    "\n",
    "# Convert the 'meanP' column to numeric, replacing commas with dots\n",
    "winter_data['meanP'] = winter_data['meanP'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# Plot the 'meanP' column\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(winter_data['meanP'], marker='o', linestyle='-', color='b')\n",
    "plt.title('MeanP during Winter Season')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('MeanP')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add all buses as nodes\n",
    "for bus in net.bus.index:\n",
    "    G.add_node(bus)\n",
    "\n",
    "# Add edges based on line connections with edge index as an attribute\n",
    "line_edges = {}\n",
    "for idx, line in enumerate(net.line.itertuples()):\n",
    "    from_bus = line.from_bus\n",
    "    to_bus = line.to_bus\n",
    "    edge = (from_bus, to_bus)\n",
    "    G.add_edge(from_bus, to_bus)\n",
    "    line_edges[edge] = f\"Line {idx}\"\n",
    "\n",
    "# Add edges for transformer connections with edge index as an attribute\n",
    "trafo_edges = {}\n",
    "for idx, trafo in enumerate(net.trafo.itertuples()):\n",
    "    hv_bus = trafo.hv_bus\n",
    "    lv_bus = trafo.lv_bus\n",
    "    edge = (hv_bus, lv_bus)\n",
    "    G.add_edge(hv_bus, lv_bus)\n",
    "    trafo_edges[edge] = f\"Trafo {idx}\"\n",
    "\n",
    "# Combine all edge indices into one dictionary\n",
    "edge_labels = {**line_edges, **trafo_edges}\n",
    "\n",
    "# Find the root bus (e.g., the slack bus or transformer bus)\n",
    "root_bus = net.ext_grid.bus.iloc[0]\n",
    "\n",
    "# Debugging: Ensure the root bus exists in the graph\n",
    "if root_bus not in G.nodes:\n",
    "    print(f\"Warning: Root bus {root_bus} is not in the graph.\")\n",
    "    print(f\"Available nodes: {list(G.nodes)}\")\n",
    "else:\n",
    "    print(f\"Root bus {root_bus} found.\")\n",
    "\n",
    "# Generate a topological sort to ensure hierarchy\n",
    "levels = {node: 0 for node in G.nodes}\n",
    "visited = set()\n",
    "\n",
    "def assign_levels(node, level):\n",
    "    if node in visited:\n",
    "        return\n",
    "    visited.add(node)\n",
    "    levels[node] = level\n",
    "    for neighbor in G.neighbors(node):\n",
    "        assign_levels(neighbor, level + 1)\n",
    "\n",
    "# Assign levels starting from the root bus\n",
    "assign_levels(root_bus, 0)\n",
    "\n",
    "# Define a position based on levels\n",
    "pos = {}\n",
    "nodes_by_level = {}\n",
    "for node, level in levels.items():\n",
    "    if level not in nodes_by_level:\n",
    "        nodes_by_level[level] = []\n",
    "    nodes_by_level[level].append(node)\n",
    "\n",
    "for level, nodes in nodes_by_level.items():\n",
    "    y = -level  # Downward hierarchy\n",
    "    x_positions = range(len(nodes))\n",
    "    for x, node in zip(x_positions, nodes):\n",
    "        pos[node] = (x, y)\n",
    "\n",
    "# Plot the graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "nx.draw(\n",
    "    G,\n",
    "    pos,\n",
    "    with_labels=True,\n",
    "    node_size=500,\n",
    "    node_color=\"lightblue\",\n",
    "    font_size=10,\n",
    "    arrowsize=10,\n",
    ")\n",
    "\n",
    "# Highlight the root bus\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=[root_bus], node_color=\"red\", node_size=700)\n",
    "\n",
    "# Add edge labels\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8, label_pos=0.5)\n",
    "\n",
    "plt.title(\"Hierarchical Representation of the Grid with Transformer Connections and Edge Indices\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandapower as pp\n",
    "# Buses and lines to remove\n",
    "buses_to_drop = [14, 34, 9, 19]\n",
    "\n",
    "# Remove lines associated with the buses to drop\n",
    "lines_to_drop = net.line[\n",
    "    (net.line.from_bus.isin(buses_to_drop)) | (net.line.to_bus.isin(buses_to_drop))\n",
    "].index\n",
    "\n",
    "# Drop the identified lines\n",
    "pp.drop_lines(net, lines_to_drop)\n",
    "\n",
    "# Drop the identified buses\n",
    "pp.drop_buses(net, buses_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add all buses as nodes\n",
    "for bus in net.bus.index:\n",
    "    G.add_node(bus)\n",
    "\n",
    "# Add edges based on line connections\n",
    "for line in net.line.itertuples():\n",
    "    from_bus = line.from_bus\n",
    "    to_bus = line.to_bus\n",
    "    G.add_edge(from_bus, to_bus)\n",
    "\n",
    "# Add edges for transformer connections\n",
    "for trafo in net.trafo.itertuples():\n",
    "    hv_bus = trafo.hv_bus\n",
    "    lv_bus = trafo.lv_bus\n",
    "    G.add_edge(hv_bus, lv_bus)\n",
    "\n",
    "# Find the root bus (e.g., the slack bus or transformer bus)\n",
    "root_bus = net.ext_grid.bus.iloc[0]\n",
    "\n",
    "# Debugging: Ensure the root bus exists in the graph\n",
    "if root_bus not in G.nodes:\n",
    "    print(f\"Warning: Root bus {root_bus} is not in the graph.\")\n",
    "    print(f\"Available nodes: {list(G.nodes)}\")\n",
    "else:\n",
    "    print(f\"Root bus {root_bus} found.\")\n",
    "\n",
    "# Generate a topological sort to ensure hierarchy\n",
    "levels = {node: 0 for node in G.nodes}\n",
    "visited = set()\n",
    "\n",
    "def assign_levels(node, level):\n",
    "    if node in visited:\n",
    "        return\n",
    "    visited.add(node)\n",
    "    levels[node] = level\n",
    "    for neighbor in G.neighbors(node):\n",
    "        assign_levels(neighbor, level + 1)\n",
    "\n",
    "# Assign levels starting from the root bus\n",
    "assign_levels(root_bus, 0)\n",
    "\n",
    "# Define a position based on levels\n",
    "pos = {}\n",
    "nodes_by_level = {}\n",
    "for node, level in levels.items():\n",
    "    if level not in nodes_by_level:\n",
    "        nodes_by_level[level] = []\n",
    "    nodes_by_level[level].append(node)\n",
    "\n",
    "for level, nodes in nodes_by_level.items():\n",
    "    y = -level  # Downward hierarchy\n",
    "    x_positions = range(len(nodes))\n",
    "    for x, node in zip(x_positions, nodes):\n",
    "        pos[node] = (x, y)\n",
    "\n",
    "# Plot the graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "nx.draw(\n",
    "    G,\n",
    "    pos,\n",
    "    with_labels=True,\n",
    "    node_size=500,\n",
    "    node_color=\"lightblue\",\n",
    "    font_size=10,\n",
    "    arrowsize=10,\n",
    ")\n",
    "\n",
    "# Highlight the root bus\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=[root_bus], node_color=\"red\", node_size=700)\n",
    "plt.title(\"Hierarchical Representation of the Grid with Transformer Connections\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constant loads to 3 kW for all loads except R11 to R18\n",
    "constant_loads = net.load.index.difference([1, 2, 3, 4, 5])  # Indices of loads R1, I2, C1, C12, C13, C14, C17, C18, C19, C20\n",
    "net.load.loc[constant_loads, 'p_mw'] = 15/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ConstControl controller to update values of the loads R11 to R18\n",
    "profile_loads = net.load.index.intersection([0, 1, 2, 3, 4, 5])  # Indices of loads R11 to R18\n",
    "const_load = control.ConstControl(net, element='load', element_index=profile_loads,\n",
    "                                  variable='p_mw', data_source=ds, profile_name=[\"mult\"]*len(profile_loads))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a power flow for the initial condition to check if the network is properly configured\n",
    "try:\n",
    "    pp.runpp(net)\n",
    "except pp.optimal_powerflow.OPFNotConverged:\n",
    "    print(\"Initial power flow did not converge. Please check the network configuration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising the outputwriter to save data to excel files in the current folder. You can change this to .json, .csv, or .pickle as well\n",
    "ow = timeseries.OutputWriter(net, output_path=\"./\", output_file_type=\".xlsx\")\n",
    "# adding vm_pu of all buses and line_loading in percent of all lines as outputs to be stored\n",
    "ow.log_variable('res_bus', 'vm_pu')\n",
    "ow.log_variable('res_line', 'loading_percent')\n",
    "ow.log_variable('res_load', 'p_mw')\n",
    "ow.log_variable('res_load', 'q_mvar')\n",
    "\n",
    "\n",
    "# starting the timeseries simulation for one day -> 96 15 min values.\n",
    "timeseries.run_timeseries(net)\n",
    "# now checkout the folders res_bus and res_line in your current working dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results\n",
    "vm_pu = pd.read_excel('res_bus/vm_pu.xlsx', index_col=0)\n",
    "loading_percent = pd.read_excel('res_line/loading_percent.xlsx', index_col=0)\n",
    "load_p_mw = pd.read_excel('res_load/p_mw.xlsx', index_col=0)\n",
    "load_q_mvar = pd.read_excel('res_load/q_mvar.xlsx', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandapower.plotting as plot\n",
    "# Plot the grid\n",
    "plot.simple_plot(net, show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Generate the plots\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(vm_pu, label=vm_pu.columns)\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Voltage Magnitude (p.u.)')\n",
    "plt.title('Voltage Magnitude over Time')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(loading_percent, label=loading_percent.columns)\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Loading Percent')\n",
    "plt.title('Line Loading over Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(load_p_mw, label=load_p_mw.columns)\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Active Power Load (MW)')\n",
    "plt.title('Active Power Load over Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(load_q_mvar, label=load_q_mvar.columns)\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Reactive Power Load (MVAr)')\n",
    "plt.title('Reactive Power Load over Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Function to recursively explore groups and datasets\n",
    "def explore_group(group, level=0):\n",
    "    indent = \"  \" * level  # Indentation for better readability\n",
    "    for key in group.keys():\n",
    "        item = group[key]\n",
    "        if isinstance(item, h5py.Group):\n",
    "            print(f\"{indent}Group: {key}\")\n",
    "            # Recursively explore the subgroup\n",
    "            explore_group(item, level + 1)\n",
    "        elif isinstance(item, h5py.Dataset):\n",
    "            print(f\"{indent}Dataset: {key}\")\n",
    "            print(f\"{indent}  Shape: {item.shape}\")\n",
    "            print(f\"{indent}  Data type: {item.dtype}\")\n",
    "            print(f\"{indent}  First 5 lines of data:\")\n",
    "            print(item[:5])  # Adjust the slicing as needed\n",
    "        else:\n",
    "            print(f\"{indent}Unknown item: {key}\")\n",
    "\n",
    "# Open the HDF5 file\n",
    "file_path = \"2020_weather.hdf5\"  # Replace with the path to your HDF5 file\n",
    "with h5py.File(file_path, \"r\") as hdf:\n",
    "    print(\"Keys in the file:\", list(hdf.keys()))\n",
    "    \n",
    "    # Access the 'WEATHER_SERVICE' group\n",
    "    key = 'WEATHER_SERVICE'\n",
    "    if key in hdf:\n",
    "        group = hdf[key]\n",
    "        print(f\"Exploring '{key}' group recursively:\")\n",
    "        explore_group(group)\n",
    "    else:\n",
    "        print(f\"Key '{key}' not found in the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "# Open the HDF5 file\n",
    "file_path = \"2020_weather.hdf5\"  # Replace with the path to your HDF5 file\n",
    "with h5py.File(file_path, \"r\") as hdf:\n",
    "    # Access the dataset for apparent temperature\n",
    "    dataset_path = \"WEATHER_SERVICE/IN/WEATHER_APPARENT_TEMPERATURE_TOTAL/table\"\n",
    "    dataset = hdf[dataset_path]\n",
    "    \n",
    "    # Convert to pandas DataFrame\n",
    "    data = pd.DataFrame(dataset[:])  # Convert structured array to DataFrame\n",
    "    # Convert 'index' field (timestamp) to datetime\n",
    "    data['index'] = pd.to_datetime(data['index'], unit='ns')\n",
    "    \n",
    "    # Filter for the first week of January 2020\n",
    "    start_date = \"2020-01-01\"\n",
    "    end_date = \"2020-01-08\"\n",
    "    filtered_data = data[(data['index'] >= start_date) & (data['index'] < end_date)]\n",
    "    \n",
    "    # Export to CSV\n",
    "    output_file = \"temperatureWinter5m.csv\"\n",
    "    filtered_data.to_csv(output_file, index=False)\n",
    "    print(f\"Filtered data for the first week of January 2020 has been saved to '{output_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "# Open the HDF5 file\n",
    "file_path = \"2020_weather.hdf5\"  # Replace with the path to your HDF5 file\n",
    "with h5py.File(file_path, \"r\") as hdf:\n",
    "    # Access the dataset for apparent temperature\n",
    "    dataset_path = \"WEATHER_SERVICE/IN/WEATHER_APPARENT_TEMPERATURE_TOTAL/table\"\n",
    "    dataset = hdf[dataset_path]\n",
    "    \n",
    "    # Convert to pandas DataFrame\n",
    "    data = pd.DataFrame(dataset[:])  # Convert structured array to DataFrame\n",
    "    # Convert 'index' field (timestamp) to datetime\n",
    "    data['index'] = pd.to_datetime(data['index'], unit='ns')\n",
    "    \n",
    "    # Filter for the first week of January 2020\n",
    "    start_date = \"2020-01-01\"\n",
    "    end_date = \"2020-01-08\"\n",
    "    filtered_data = data[(data['index'] >= start_date) & (data['index'] < end_date)]\n",
    "    \n",
    "    # Set the 'index' column as the DataFrame index\n",
    "    filtered_data.set_index('index', inplace=True)\n",
    "    \n",
    "    # Resample to 15-minute intervals and calculate the mean\n",
    "    resampled_data = filtered_data.resample('15T').mean()\n",
    "    \n",
    "    # Export to CSV\n",
    "    output_file = \"temperatureWinter15m.csv\"\n",
    "    resampled_data.to_csv(output_file)\n",
    "    print(f\"15-minute resolution data for the first week of January 2020 has been saved to '{output_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "# Open the HDF5 file\n",
    "file_path = \"2020_weather.hdf5\"  # Replace with the path to your HDF5 file\n",
    "with h5py.File(file_path, \"r\") as hdf:\n",
    "    # Access the dataset for apparent temperature\n",
    "    dataset_path = \"WEATHER_SERVICE/IN/WEATHER_APPARENT_TEMPERATURE_TOTAL/table\"\n",
    "    dataset = hdf[dataset_path]\n",
    "    \n",
    "    # Convert to pandas DataFrame\n",
    "    data = pd.DataFrame(dataset[:])  # Convert structured array to DataFrame\n",
    "    # Convert 'index' field (timestamp) to datetime\n",
    "    data['index'] = pd.to_datetime(data['index'], unit='ns')\n",
    "    \n",
    "    # Filter for the first week of January 2020\n",
    "    start_date = \"2020-01-01\"\n",
    "    end_date = \"2020-01-08\"\n",
    "    filtered_data = data[(data['index'] >= start_date) & (data['index'] < end_date)]\n",
    "    \n",
    "    # Set the 'index' column as the DataFrame index\n",
    "    filtered_data.set_index('index', inplace=True)\n",
    "    \n",
    "    # Resample to 1-hour intervals and calculate the mean\n",
    "    resampled_data = filtered_data.resample('1H').mean()\n",
    "    \n",
    "    # Export to CSV\n",
    "    output_file = \"temperatureWinter1h.csv\"\n",
    "    resampled_data.to_csv(output_file)\n",
    "    print(f\"1-hour resolution data for the first week of January 2020 has been saved to '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the CSV file\n",
    "file_path = \"heatpumpPrognosis.csv\"  # Replace with the correct path to your CSV file\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Print the first few lines\n",
    "print(\"First few lines of the 1-hour resolution data:\")\n",
    "print(df.head())\n",
    "# Print the length of the DataFrame\n",
    "print(f\"The number of rows in the DataFrame: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your CSV file\n",
    "file_path = \"heatpumpPrognosis.csv\"  # Replace with your actual file path\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "df = pd.read_csv(file_path, sep=\";\")  # Adjust the separator if needed\n",
    "\n",
    "# Clean and convert numeric columns safely\n",
    "for col in ['meanP', 'stdP', 'meanQ', 'stdQ']:\n",
    "    # Replace commas with dots and remove whitespace\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        .astype(str)  # Ensure all values are strings\n",
    "        .str.replace(r'\\s+', '', regex=True)  # Remove spaces\n",
    "        .str.replace(',', '.')  # Replace commas with dots\n",
    "    )\n",
    "    # Convert to float\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Check for NaN values after conversion\n",
    "if df[['meanP', 'stdP', 'meanQ', 'stdQ']].isnull().any().any():\n",
    "    print(\"Warning: Some values could not be converted to numeric and are NaN.\")\n",
    "\n",
    "# Preserve the custom order of seasons\n",
    "season_order = ['winter', 'summer', 'interim']\n",
    "df['season'] = pd.Categorical(df['season'], categories=season_order, ordered=True)\n",
    "\n",
    "# Group by 'season', 'dayOfWeek', and 'hour' (discard 'minute' for 1-hour resolution)\n",
    "resampled_df = df.groupby(['season', 'dayOfWeek', 'hour']).mean().reset_index()\n",
    "\n",
    "# Drop unnecessary columns\n",
    "resampled_df = resampled_df.drop(columns=['minute', 'Unnamed: 0'], errors='ignore')\n",
    "\n",
    "# Sort the DataFrame to ensure the order of seasons is maintained\n",
    "resampled_df = resampled_df.sort_values(by=['season', 'dayOfWeek', 'hour'])\n",
    "\n",
    "# Export the resampled data to a new CSV file\n",
    "output_file = \"heatpumpPrognosis1h.csv\"\n",
    "resampled_df.to_csv(output_file, sep=\";\", index=False)\n",
    "print(f\"Resampled data has been saved to '{output_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the CSV file\n",
    "file_path = \"temperatureWinter1h.csv\"  # Replace with the correct path to your CSV file\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Print the first few lines\n",
    "print(\"First few lines of the 1-hour resolution data:\")\n",
    "print(df.head())\n",
    "# Print the length of the DataFrame\n",
    "print(f\"The number of rows in the DataFrame: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_amb = df['APPARENT_TEMPERATURE:TOTAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(T_amb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pandapipes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
